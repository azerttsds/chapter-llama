{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lutils import openf, writef\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().cwd().parent.parent))\n",
    "from src.data.utils_asr import ChaptersASR\n",
    "from tools.captions.caption_selection import (\n",
    "    CaptionSelection,\n",
    "    select_furthest_timestamps,\n",
    ")\n",
    "\n",
    "base_dir = Path(\"../../\")\n",
    "vidc_dir = base_dir / \"dataset/\"\n",
    "\n",
    "subset = \"sml1k_train\"\n",
    "subset = \"sml300_val\"\n",
    "captions_dir = vidc_dir / \"captions/HwwwH_MiniCPM-V-2/all\"\n",
    "video_ids = openf(vidc_dir / f\"docs/subset_data/{subset}.json\")\n",
    "\n",
    "chapters = ChaptersASR(vidc_dir=vidc_dir, subset=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.captions.caption_selection import (\n",
    "    ASRPreds,\n",
    "    get_interval_timestamps,\n",
    "    get_n_timestamps,\n",
    ")\n",
    "\n",
    "model = \"Meta-Llama-3.2-11B-Vision-Instruct\"\n",
    "model = \"Llama-3.2-1B-Instruct\"\n",
    "model = \"Llama-3.2-3B-Instruct\"\n",
    "model = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "subset_train = \"s8k-2_train\"\n",
    "subset_train = \"sml10k-2_train\"\n",
    "subset_train = \"s1k-2_train\"\n",
    "subset_train = \"s10k-2_train\"\n",
    "asr_preds = ASRPreds(subset_train=subset_train, base_dir=base_dir, model=model)\n",
    "\n",
    "\n",
    "def cs_asr(vid_id):\n",
    "    return asr_preds.get_timestamps(vid_id)\n",
    "\n",
    "\n",
    "def cs_10s(vid_id):\n",
    "    duration = chapters.get_duration(vid_id)\n",
    "    return get_interval_timestamps(duration, 10)\n",
    "\n",
    "\n",
    "def cs_100f(vid_id):\n",
    "    duration = chapters.get_duration(vid_id)\n",
    "    return get_n_timestamps(duration, 100)\n",
    "\n",
    "\n",
    "def cs_10f(vid_id):\n",
    "    duration = chapters.get_duration(vid_id)\n",
    "    return get_n_timestamps(duration, 10)\n",
    "\n",
    "\n",
    "cs = CaptionSelection(\n",
    "    sampling_methods=(\"shot-boundary\",), base_dir=base_dir, vidc_dir=vidc_dir\n",
    ")\n",
    "\n",
    "\n",
    "def cs_sd(vid_id):\n",
    "    duration = chapters.get_duration(vid_id)\n",
    "    return cs(vid_id, duration)\n",
    "\n",
    "\n",
    "model = \"gemini-1.5-pro\"\n",
    "model = \"gemini-2.0-flash\"\n",
    "model = \"gpt-4o-mini\"\n",
    "model = \"gpt-4o\"\n",
    "cs_proprietary = ASRPreds(subset_train=\"zero-shot\", base_dir=base_dir, model=model)\n",
    "\n",
    "\n",
    "cs_captions_preds = ASRPreds(\n",
    "    base_dir=base_dir,\n",
    "    prompt=\"captions\",\n",
    "    data_flags=\"10s\",\n",
    "    subset_train=\"s1k-2_no-asr_train\",\n",
    ")\n",
    "\n",
    "\n",
    "def cs_midpoints(vid_id):\n",
    "    if vid_id not in asr_preds:\n",
    "        return None\n",
    "    timestamps = cs_asr(vid_id)\n",
    "    if not timestamps:\n",
    "        return None\n",
    "    vid_duration = chapters.get_duration(vid_id)\n",
    "    timestamps = [0] + timestamps[1:]\n",
    "    timestamps = (\n",
    "        timestamps + [vid_duration] if timestamps[-1] != vid_duration else timestamps\n",
    "    )\n",
    "    timestamps_midpoints = [\n",
    "        (s1 + s2) / 2 for s1, s2 in zip(timestamps[:-1], timestamps[1:])\n",
    "    ]\n",
    "    return timestamps_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 649.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos needing predictions: 0\n",
      "Total number of missing captions needed: 407\n",
      "\n",
      "Per video statistics:\n",
      "Average missing captions per video: 4.0\n",
      "Max missing captions for a video: 38\n",
      "Min missing captions for a video: 1\n",
      "Number of videos needing captions: 101\n",
      "Percentage of videos not found: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id2timestamps = {}\n",
    "vid_need_preds = []\n",
    "for vid_id in tqdm(video_ids):\n",
    "    vid_duration = chapters.get_duration(vid_id)\n",
    "\n",
    "    if vid_id in chapters:\n",
    "        # timestamps_s = cs_sd(vid_id) if vid_id in asr_preds else None\n",
    "        # timestamps_s = cs_10f(vid_id)\n",
    "        # timestamps_s = cs_proprietary(vid_id)\n",
    "        timestamps_s = cs_asr(vid_id) if vid_id in asr_preds else None\n",
    "        # timestamps_s = cs_midpoints(vid_id)\n",
    "        if not timestamps_s:\n",
    "            # assert timestamps_s, f\"{vid_id} has ASR preds but no predictions\"\n",
    "            vid_need_preds.append(vid_id)\n",
    "            continue\n",
    "    else:\n",
    "        timestamps_s = cs_10s(vid_id) if vid_duration < 60 * 10 else cs_100f(vid_id)\n",
    "    timestamps_s = select_furthest_timestamps(timestamps_s)\n",
    "\n",
    "    timestamps_s = [t for t in timestamps_s if t < vid_duration]\n",
    "\n",
    "    caption_pth = captions_dir / f\"{vid_id[:2]}\" / f\"{vid_id}.json\"\n",
    "\n",
    "    if not caption_pth.exists():\n",
    "        id2timestamps[vid_id] = timestamps_s\n",
    "        continue\n",
    "\n",
    "    vid_captions = openf(caption_pth)\n",
    "    n_frames = int(list(vid_captions.keys())[0].split(\"/\")[1])\n",
    "    vid_timestamps = [\n",
    "        int(frm.split(\"/\")[0]) * vid_duration / n_frames for frm in vid_captions\n",
    "    ]\n",
    "\n",
    "    todo_timestamps = []\n",
    "    for t in timestamps_s:\n",
    "        # Check if there's any existing timestamp within 1 second\n",
    "        if not any(abs(t - vt) < 2.0 for vt in vid_timestamps):\n",
    "            todo_timestamps.append(t)\n",
    "\n",
    "    if todo_timestamps:\n",
    "        id2timestamps[vid_id] = todo_timestamps\n",
    "\n",
    "\n",
    "print(f\"Number of videos needing predictions: {len(vid_need_preds)}\")\n",
    "\n",
    "# Calculate total number of missing captions needed\n",
    "total_missing = sum(len(timestamps) for timestamps in id2timestamps.values())\n",
    "print(f\"Total number of missing captions needed: {total_missing}\")\n",
    "\n",
    "# Calculate statistics per video\n",
    "missing_per_video = {\n",
    "    vid_id: len(timestamps) for vid_id, timestamps in id2timestamps.items()\n",
    "}\n",
    "if missing_per_video:\n",
    "    avg_missing = sum(missing_per_video.values()) / len(missing_per_video)\n",
    "    max_missing = max(missing_per_video.values())\n",
    "    min_missing = min(missing_per_video.values())\n",
    "    print(\"\\nPer video statistics:\")\n",
    "    print(f\"Average missing captions per video: {avg_missing:.1f}\")\n",
    "    print(f\"Max missing captions for a video: {max_missing}\")\n",
    "    print(f\"Min missing captions for a video: {min_missing}\")\n",
    "    print(f\"Number of videos needing captions: {len(missing_per_video)}\")\n",
    "\n",
    "\n",
    "not_found = sum([1 for vid_id in video_ids if vid_id not in chapters])\n",
    "print(f\"Percentage of videos not found: {not_found / len(video_ids):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = vidc_dir / \"captions/missing_timestamps\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "writef(id2timestamps, out_dir / f\"{subset}_0.json\")\n",
    "print(f\"python tools/captions/caption_frames_timestamp.py 0 --subset={subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing missing timestamps to /storage/lucas/datasets/VidChapters/captions/missing_timestamps\n",
      "Part 1/8: 12 videos\n",
      "Part 8/8: 17 videos\n",
      "Change subset for sml300_val\n",
      "Change #SBATCH --array=0-7\n",
      "git push and git pull\n",
      "bash /lustre/fswork/projects/rech/cyq/ucp99db/datasets/VidChapters2/captions/HwwwH_MiniCPM-V-2/send_captions.sh 10000\n",
      "rm -rf /lustre/fswork/projects/rech/cyq/ucp99db/datasets/VidChapters2/captions//missing_timestamps\n",
      "scp -r athena:/storage/lucas/datasets/VidChapters/captions/missing_timestamps/ /lustre/fswork/projects/rech/cyq/ucp99db/datasets/VidChapters2/captions/\n",
      "rm -rf /lustre/fswork/projects/rech/cyq/ucp99db/datasets/VidChapters2/captions/HwwwH_MiniCPM-V-2/all-missing\n",
      "sbatch tools/captions/run_captions_v100.sh --subset sml300_val\n"
     ]
    }
   ],
   "source": [
    "out_dir = vidc_dir / \"captions/missing_timestamps\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# delete existing files\n",
    "for pth in out_dir.glob(\"*.json\"):\n",
    "    pth.unlink()\n",
    "\n",
    "print(f\"Writing missing timestamps to {out_dir.resolve()}\")\n",
    "\n",
    "# Split data into n_files shards\n",
    "num_parts = 8\n",
    "total_items = len(id2timestamps)\n",
    "part_size = total_items // num_parts\n",
    "items = list(id2timestamps.items())\n",
    "\n",
    "for i in range(num_parts):\n",
    "    # Determine the start and end index for this part\n",
    "    start_idx = i * part_size\n",
    "    # Ensure the last part takes the remaining items in case of rounding issues\n",
    "    end_idx = (i + 1) * part_size if i < num_parts - 1 else total_items\n",
    "\n",
    "    partial_dict = dict(items[start_idx:end_idx])\n",
    "\n",
    "    out_pth = out_dir / f\"{chapters.subset}_{i}.json\"\n",
    "    writef(out_pth, partial_dict)\n",
    "\n",
    "# print length of each part\n",
    "for i in [0, num_parts - 1]:\n",
    "    out_pth = out_dir / f\"{chapters.subset}_{i}.json\"\n",
    "    print(f\"Part {i + 1}/{num_parts}: {len(openf(out_pth))} videos\")\n",
    "\n",
    "\n",
    "print(f\"Change subset for {chapters.subset}\")\n",
    "print(f\"Change #SBATCH --array={0}-{i}\")\n",
    "print(\"git push and git pull\")\n",
    "\n",
    "captions_dir = \"path/to/datasets/VidChapters/captions/\"\n",
    "print(f\"rm -rf {captions_dir}/HwwwH_MiniCPM-V-2/all-missing\")\n",
    "print(f\"sbatch tools/captions/run_captions_v100.sh --subset {chapters.subset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
